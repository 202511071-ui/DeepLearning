{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAdNHyfrznhM",
        "outputId": "a14df2fd-6ce3-44dd-bae2-bbdfa860f259"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-02-20 11:28:41--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2026-02-20 11:28:42--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2026-02-20 11:28:42--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.12MB/s    in 2m 39s  \n",
            "\n",
            "2026-02-20 11:31:22 (5.16 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ],
      "source": [
        "\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #  TASK:-1"
      ],
      "metadata": {
        "id": "IDzQNjiOBMWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/movies - movies.csv')\n",
        "\n",
        "\n",
        "allowed_cols = ['overview', 'tagline', 'keywords', 'genres', 'vote_average']\n",
        "df = df[allowed_cols]\n",
        "\n",
        "print(f\"Initial dataset shape: {df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLyLLxbL1lAh",
        "outputId": "273c9bac-e2e5-469a-dacf-2d145f61ba6e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial dataset shape: (4803, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    tokens = text.split()\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "text_columns = ['overview', 'tagline', 'keywords']\n",
        "for col in text_columns:\n",
        "    df[col] = df[col].apply(preprocess_text)\n",
        "\n",
        "print(\"Preprocessing complete. Example overview:\")\n",
        "print(df['overview'].iloc[0][:100] + \"...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-u6hWyHs2Mrw",
        "outputId": "0a9cb490-fc66-4da9-f72a-dd0dc650bf85"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing complete. Example overview:\n",
            "in the nd century a paraplegic marine is dispatched to the moon pandora on a unique mission but beco...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_df, temp_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.30,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "val_df, test_df = train_test_split(\n",
        "    temp_df,\n",
        "    test_size=0.50,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Train set size: {len(train_df)}\")\n",
        "print(f\"Validation set size: {len(val_df)}\")\n",
        "print(f\"Test set size: {len(test_df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvmktlSz2XOE",
        "outputId": "e4b26cce-3c56-4663-f65f-524b904418d2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 3362\n",
            "Validation set size: 720\n",
            "Test set size: 721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TASK:-2"
      ],
      "metadata": {
        "id": "dRflQf4kBHrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_glove_embeddings(path):\n",
        "    embeddings_dict = {}\n",
        "    with open(path, 'r', encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vector = np.asarray(values[1:], \"float32\")\n",
        "            embeddings_dict[word] = vector\n",
        "    return embeddings_dict\n",
        "\n",
        "\n",
        "glove_path = '/content/glove.6B.100d.txt'\n",
        "glove_index = load_glove_embeddings(glove_path)\n",
        "print(f\"Loaded {len(glove_index)} word vectors.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KVJHiJQ2cKA",
        "outputId": "90fce48c-10dc-4459-d3fe-c837e219f849"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_coverage(df, text_col, embeddings):\n",
        "    all_tokens = \" \".join(df[text_col]).split()\n",
        "    unique_tokens = set(all_tokens)\n",
        "    covered = [w for w in unique_tokens if w in embeddings]\n",
        "\n",
        "    coverage_pct = (len(covered) / len(unique_tokens)) * 100\n",
        "    print(f\"Coverage for '{text_col}': {len(covered)}/{len(unique_tokens)} ({coverage_pct:.2f}%)\")\n",
        "    return coverage_pct\n",
        "\n",
        "\n",
        "coverage = check_coverage(train_df, 'overview', glove_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLNtJbLE2lIB",
        "outputId": "29b785b0-b943-455b-fcf0-aa923493ea66"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coverage for 'overview': 17304/19226 (90.00%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=10000, stop_words='english')\n",
        "tfidf.fit(train_df['overview'])\n",
        "feature_names = tfidf.get_feature_names_out()\n",
        "word_to_tfidf_idx = {word: i for i, word in enumerate(feature_names)}\n",
        "\n",
        "def get_weighted_doc_embedding(text, embeddings, tfidf_model, word_map):\n",
        "    tokens = text.split()\n",
        "    if not tokens:\n",
        "        return np.zeros(100)\n",
        "\n",
        "\n",
        "    tfidf_vector = tfidf_model.transform([text]).toarray()[0]\n",
        "\n",
        "    vectors = []\n",
        "    weights = []\n",
        "\n",
        "    for word in tokens:\n",
        "        if word in embeddings and word in word_map:\n",
        "            vectors.append(embeddings[word])\n",
        "\n",
        "            weights.append(tfidf_vector[word_map[word]])\n",
        "\n",
        "    if not vectors or sum(weights) == 0:\n",
        "\n",
        "        available_vectors = [embeddings[w] for w in tokens if w in embeddings]\n",
        "        return np.mean(available_vectors, axis=0) if available_vectors else np.zeros(100)\n",
        "\n",
        "\n",
        "    return np.average(vectors, axis=0, weights=weights)\n",
        "\n",
        "X_train = np.array([get_weighted_doc_embedding(t, glove_index, tfidf, word_to_tfidf_idx) for t in train_df['overview']])\n",
        "X_val = np.array([get_weighted_doc_embedding(t, glove_index, tfidf, word_to_tfidf_idx) for t in val_df['overview']])\n",
        "X_test = np.array([get_weighted_doc_embedding(t, glove_index, tfidf, word_to_tfidf_idx) for t in test_df['overview']])\n",
        "\n",
        "print(f\"Final feature shape: {X_train.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m18rNzL52osF",
        "outputId": "523290a8-fd53-48f9-cdaf-e014bc34cda7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final feature shape: (3362, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TASK:-3"
      ],
      "metadata": {
        "id": "EZWvvgx9BBKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "\n",
        "y_train_reg = torch.tensor(train_df['vote_average'].values, dtype=torch.float32).view(-1, 1)\n",
        "y_test_reg = torch.tensor(test_df['vote_average'].values, dtype=torch.float32).view(-1, 1)"
      ],
      "metadata": {
        "id": "pivFM4rC2rpX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RatingRegressor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RatingRegressor, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(100, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "model_a = RatingRegressor()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model_a.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "CEONfeh1226D"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "global_mean = train_df['vote_average'].mean()\n",
        "baseline_preds = np.full(y_test_reg.shape, global_mean)\n",
        "baseline_mse = mean_squared_error(y_test_reg, baseline_preds)\n",
        "print(f\"Baseline MSE: {baseline_mse:.4f}\")\n",
        "print(f\"Baseline RMSE: {np.sqrt(baseline_mse):.4f}\")\n",
        "\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    model_a.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model_a(X_train_tensor)\n",
        "    loss = criterion(outputs, y_train_reg)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTQJITnL29KF",
        "outputId": "2791b028-b281-4902-ddad-e044c37d6e0b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline MSE: 1.2825\n",
            "Baseline RMSE: 1.1325\n",
            "Epoch [10/50], Loss: 33.8949\n",
            "Epoch [20/50], Loss: 28.1795\n",
            "Epoch [30/50], Loss: 18.6104\n",
            "Epoch [40/50], Loss: 7.1498\n",
            "Epoch [50/50], Loss: 2.2868\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_a.eval()\n",
        "with torch.no_grad():\n",
        "    test_outputs = model_a(X_test_tensor)\n",
        "    mse = criterion(test_outputs, y_test_reg).item()\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "print(f\"\\nModel A (Overview) Results:\")\n",
        "print(f\"Test MSE: {mse:.4f}\")\n",
        "print(f\"Test RMSE: {rmse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-KcfP883Clm",
        "outputId": "06328b72-fe76-4594-e592-9b6e164f1856"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model A (Overview) Results:\n",
            "Test MSE: 2.2983\n",
            "Test RMSE: 1.5160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TASK:-4"
      ],
      "metadata": {
        "id": "_DPYqAiF7BbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b307594",
        "outputId": "80bc606a-1702-4147-9f5e-207fdab8bf84"
      },
      "source": [
        "import ast\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, hamming_loss, jaccard_score\n",
        "\n",
        "def parse_genres(genre_str):\n",
        "    if not isinstance(genre_str, str) or genre_str.strip() == \"\":\n",
        "        return []\n",
        "    try:\n",
        "        genres_list = ast.literal_eval(genre_str)\n",
        "        return [genre['name'] for genre in genres_list if 'name' in genre]\n",
        "    except (ValueError, SyntaxError, TypeError):\n",
        "        return []\n",
        "\n",
        "train_df['parsed_genres'] = train_df['genres'].apply(parse_genres)\n",
        "test_df['parsed_genres'] = test_df['genres'].apply(parse_genres)\n",
        "\n",
        "non_empty_parsed_train = train_df[train_df['parsed_genres'].apply(len) > 0]['parsed_genres']\n",
        "if not non_empty_parsed_train.empty:\n",
        "    print(f\"Example of parsed genres (train): {non_empty_parsed_train.iloc[0]}\")\n",
        "else:\n",
        "    print(\"No genres were successfully parsed in the training set.\")\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "\n",
        "y_train_gen = mlb.fit_transform(train_df['parsed_genres'])\n",
        "\n",
        "\n",
        "y_test_gen = mlb.transform(test_df['parsed_genres'])\n",
        "\n",
        "\n",
        "print(f\"Total unique genres: {len(mlb.classes_)}\")\n",
        "print(f\"Shape of y_train_gen: {y_train_gen.shape}\")\n",
        "print(f\"Shape of y_test_gen: {y_test_gen.shape}\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No genres were successfully parsed in the training set.\n",
            "Total unique genres: 0\n",
            "Shape of y_train_gen: (3362, 0)\n",
            "Shape of y_test_gen: (721, 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2af23171",
        "outputId": "1b5f089e-73eb-4501-c9fe-78ef07638231"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "print(\"Sample of raw 'genres' column from df:\")\n",
        "print(df['genres'].head(10))\n",
        "\n",
        "\n",
        "print(\"\\nValue counts for 'genres' column types:\")\n",
        "print(df['genres'].apply(type).value_counts())\n",
        "\n",
        "print(\"\\nNumber of NaN values in 'genres' column:\")\n",
        "print(df['genres'].isnull().sum())"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample of raw 'genres' column from df:\n",
            "0    Action Adventure Fantasy Science Fiction\n",
            "1                    Adventure Fantasy Action\n",
            "2                      Action Adventure Crime\n",
            "3                 Action Crime Drama Thriller\n",
            "4            Action Adventure Science Fiction\n",
            "5                    Fantasy Action Adventure\n",
            "6                            Animation Family\n",
            "7            Action Adventure Science Fiction\n",
            "8                    Adventure Fantasy Family\n",
            "9                    Action Adventure Fantasy\n",
            "Name: genres, dtype: object\n",
            "\n",
            "Value counts for 'genres' column types:\n",
            "genres\n",
            "<class 'str'>      4775\n",
            "<class 'float'>      28\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Number of NaN values in 'genres' column:\n",
            "28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fOQxNneiAqn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcebfb84",
        "outputId": "276e06c1-b425-4db2-cbb2-d558d2c90236"
      },
      "source": [
        "import ast\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, hamming_loss, jaccard_score\n",
        "\n",
        "\n",
        "def parse_genres(genre_str):\n",
        "    if not isinstance(genre_str, str) or genre_str.strip() == \"\":\n",
        "        return []\n",
        "    return genre_str.split()\n",
        "\n",
        "\n",
        "train_df['parsed_genres'] = train_df['genres'].apply(parse_genres)\n",
        "test_df['parsed_genres'] = test_df['genres'].apply(parse_genres)\n",
        "\n",
        "\n",
        "non_empty_parsed_train = train_df[train_df['parsed_genres'].apply(len) > 0]['parsed_genres']\n",
        "if not non_empty_parsed_train.empty:\n",
        "    print(f\"Example of parsed genres (train): {non_empty_parsed_train.iloc[0]}\")\n",
        "else:\n",
        "    print(\"No genres were successfully parsed in the training set.\")\n",
        "\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "\n",
        "y_train_gen = mlb.fit_transform(train_df['parsed_genres'])\n",
        "\n",
        "y_test_gen = mlb.transform(test_df['parsed_genres'])\n",
        "\n",
        "\n",
        "print(f\"Total unique genres: {len(mlb.classes_)}\")\n",
        "print(f\"Shape of y_train_gen: {y_train_gen.shape}\")\n",
        "print(f\"Shape of y_test_gen: {y_test_gen.shape}\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example of parsed genres (train): ['Mystery', 'Thriller']\n",
            "Total unique genres: 22\n",
            "Shape of y_train_gen: (3362, 22)\n",
            "Shape of y_test_gen: (721, 22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09f3af83",
        "outputId": "8ac75c6a-6a67-431b-c6a7-bef194ba6866"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "X_train_tagline = np.array([get_weighted_doc_embedding(t, glove_index, tfidf, word_to_tfidf_idx) for t in train_df['tagline']])\n",
        "X_val_tagline = np.array([get_weighted_doc_embedding(t, glove_index, tfidf, word_to_tfidf_idx) for t in val_df['tagline']])\n",
        "X_test_tagline = np.array([get_weighted_doc_embedding(t, glove_index, tfidf, word_to_tfidf_idx) for t in test_df['tagline']])\n",
        "\n",
        "print(f\"Tagline embeddings for training set shape: {X_train_tagline.shape}\")\n",
        "print(f\"Tagline embeddings for validation set shape: {X_val_tagline.shape}\")\n",
        "print(f\"Tagline embeddings for test set shape: {X_test_tagline.shape}\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tagline embeddings for training set shape: (3362, 100)\n",
            "Tagline embeddings for validation set shape: (720, 100)\n",
            "Tagline embeddings for test set shape: (721, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02ca7007",
        "outputId": "39c048ff-5611-4572-c982-2775e574eca8"
      },
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, hamming_loss\n",
        "import numpy as np\n",
        "\n",
        "def train_and_evaluate_multilabel_model(X_train_data, y_train_data, X_test_data, y_test_data, model_name):\n",
        "    print(f\"\\n--- Training and Evaluating Model: {model_name} ---\")\n",
        "\n",
        "\n",
        "    model = OneVsRestClassifier(LogisticRegression(solver='lbfgs', max_iter=1000, random_state=42))\n",
        "\n",
        "\n",
        "    model.fit(X_train_data, y_train_data)\n",
        "\n",
        "    y_pred = model.predict(X_test_data)\n",
        "\n",
        "\n",
        "    micro_f1 = f1_score(y_test_data, y_pred, average='micro')\n",
        "    macro_f1 = f1_score(y_test_data, y_pred, average='macro')\n",
        "    h_loss = hamming_loss(y_test_data, y_pred)\n",
        "\n",
        "    print(f\"Micro-F1 Score: {micro_f1:.4f}\")\n",
        "    print(f\"Macro-F1 Score: {macro_f1:.4f}\")\n",
        "    print(f\"Hamming Loss: {h_loss:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'model_name': model_name,\n",
        "        'micro_f1': micro_f1,\n",
        "        'macro_f1': macro_f1,\n",
        "        'hamming_loss': h_loss\n",
        "    }\n",
        "\n",
        "results_overview = train_and_evaluate_multilabel_model(\n",
        "    X_train, y_train_gen, X_test, y_test_gen, 'Overview Embeddings'\n",
        ")\n",
        "\n",
        "\n",
        "results_tagline = train_and_evaluate_multilabel_model(\n",
        "    X_train_tagline, y_train_gen, X_test_tagline, y_test_gen, 'Tagline Embeddings'\n",
        ")\n",
        "\n",
        "print(\"\\n--- Comparison of Models ---\")\n",
        "print(f\"Overview Embeddings - Micro-F1: {results_overview['micro_f1']:.4f}, Macro-F1: {results_overview['macro_f1']:.4f}, Hamming Loss: {results_overview['hamming_loss']:.4f}\")\n",
        "print(f\"Tagline Embeddings - Micro-F1: {results_tagline['micro_f1']:.4f}, Macro-F1: {results_tagline['macro_f1']:.4f}, Hamming Loss: {results_tagline['hamming_loss']:.4f}\")\n",
        "\n",
        "if results_overview['micro_f1'] > results_tagline['micro_f1']:\n",
        "    print(\"\\nModel with 'Overview Embeddings' performs better based on Micro-F1 score.\")\n",
        "elif results_tagline['micro_f1'] > results_overview['micro_f1']:\n",
        "    print(\"\\nModel with 'Tagline Embeddings' performs better based on Micro-F1 score.\")\n",
        "else:\n",
        "    print(\"\\nBoth models perform similarly based on Micro-F1 score.\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training and Evaluating Model: Overview Embeddings ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Micro-F1 Score: 0.4773\n",
            "Macro-F1 Score: 0.2999\n",
            "Hamming Loss: 0.1018\n",
            "\n",
            "--- Training and Evaluating Model: Tagline Embeddings ---\n",
            "Micro-F1 Score: 0.3011\n",
            "Macro-F1 Score: 0.1153\n",
            "Hamming Loss: 0.1168\n",
            "\n",
            "--- Comparison of Models ---\n",
            "Overview Embeddings - Micro-F1: 0.4773, Macro-F1: 0.2999, Hamming Loss: 0.1018\n",
            "Tagline Embeddings - Micro-F1: 0.3011, Macro-F1: 0.1153, Hamming Loss: 0.1168\n",
            "\n",
            "Model with 'Overview Embeddings' performs better based on Micro-F1 score.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a96bc310",
        "outputId": "b9daad41-b367-44d3-953c-c4f05654a115"
      },
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, hamming_loss\n",
        "import numpy as np\n",
        "\n",
        "def train_and_evaluate_multilabel_model(X_train_data, y_train_data, X_test_data, y_test_data, model_name):\n",
        "    print(f\"\\n--- Training and Evaluating Model: {model_name} ---\")\n",
        "\n",
        "\n",
        "    model = OneVsRestClassifier(LogisticRegression(solver='lbfgs', max_iter=1000, random_state=42))\n",
        "\n",
        "\n",
        "    model.fit(X_train_data, y_train_data)\n",
        "\n",
        "\n",
        "    y_pred = model.predict(X_test_data)\n",
        "\n",
        "\n",
        "    micro_f1 = f1_score(y_test_data, y_pred, average='micro', zero_division=0)\n",
        "    macro_f1 = f1_score(y_test_data, y_pred, average='macro', zero_division=0)\n",
        "    h_loss = hamming_loss(y_test_data, y_pred)\n",
        "\n",
        "    print(f\"Micro-F1 Score: {micro_f1:.4f}\")\n",
        "    print(f\"Macro-F1 Score: {macro_f1:.4f}\")\n",
        "    print(f\"Hamming Loss: {h_loss:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'model_name': model_name,\n",
        "        'micro_f1': micro_f1,\n",
        "        'macro_f1': macro_f1,\n",
        "        'hamming_loss': h_loss\n",
        "    }\n",
        "\n",
        "results_overview = train_and_evaluate_multilabel_model(\n",
        "    X_train, y_train_gen, X_test, y_test_gen, 'Overview Embeddings'\n",
        ")\n",
        "\n",
        "\n",
        "results_tagline = train_and_evaluate_multilabel_model(\n",
        "    X_train_tagline, y_train_gen, X_test_tagline, y_test_gen, 'Tagline Embeddings'\n",
        ")\n",
        "\n",
        "print(\"\\n--- Comparison of Models ---\")\n",
        "print(f\"Overview Embeddings - Micro-F1: {results_overview['micro_f1']:.4f}, Macro-F1: {results_overview['macro_f1']:.4f}, Hamming Loss: {results_overview['hamming_loss']:.4f}\")\n",
        "print(f\"Tagline Embeddings - Micro-F1: {results_tagline['micro_f1']:.4f}, Macro-F1: {results_tagline['macro_f1']:.4f}, Hamming Loss: {results_tagline['hamming_loss']:.4f}\")\n",
        "\n",
        "if results_overview['micro_f1'] > results_tagline['micro_f1']:\n",
        "    print(\"\\nModel with 'Overview Embeddings' performs better based on Micro-F1 score.\")\n",
        "elif results_tagline['micro_f1'] > results_overview['micro_f1']:\n",
        "    print(\"\\nModel with 'Tagline Embeddings' performs better based on Micro-F1 score.\")\n",
        "else:\n",
        "    print(\"\\nBoth models perform similarly based on Micro-F1 score.\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training and Evaluating Model: Overview Embeddings ---\n",
            "Micro-F1 Score: 0.4773\n",
            "Macro-F1 Score: 0.2999\n",
            "Hamming Loss: 0.1018\n",
            "\n",
            "--- Training and Evaluating Model: Tagline Embeddings ---\n",
            "Micro-F1 Score: 0.3011\n",
            "Macro-F1 Score: 0.1153\n",
            "Hamming Loss: 0.1168\n",
            "\n",
            "--- Comparison of Models ---\n",
            "Overview Embeddings - Micro-F1: 0.4773, Macro-F1: 0.2999, Hamming Loss: 0.1018\n",
            "Tagline Embeddings - Micro-F1: 0.3011, Macro-F1: 0.1153, Hamming Loss: 0.1168\n",
            "\n",
            "Model with 'Overview Embeddings' performs better based on Micro-F1 score.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TASK:-5"
      ],
      "metadata": {
        "id": "RZyhi-wXAcs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e1d56e1",
        "outputId": "019463ee-7a3a-43e7-e64f-fcd53dba2c7c"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "genre_names = mlb.classes_\n",
        "\n",
        "genre_words = {genre: [] for genre in genre_names}\n",
        "\n",
        "\n",
        "for idx, row in train_df.iterrows():\n",
        "\n",
        "    overview_text = row['overview']\n",
        "\n",
        "\n",
        "    words = overview_text.split()\n",
        "\n",
        "\n",
        "    movie_genre_labels = y_train_gen[train_df.index.get_loc(idx)]\n",
        "\n",
        "\n",
        "    for i, is_genre in enumerate(movie_genre_labels):\n",
        "        if is_genre == 1:\n",
        "            genre_name = genre_names[i]\n",
        "            genre_words[genre_name].extend(words)\n",
        "\n",
        "print(f\"Initialized genre_words dictionary with {len(genre_words)} genres.\")\n",
        "\n",
        "if 'Action' in genre_words:\n",
        "    print(f\"Sample words for 'Action' genre: {genre_words['Action'][:20]}...\")\n",
        "else:\n",
        "    print(\"No 'Action' genre found or processed.\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized genre_words dictionary with 22 genres.\n",
            "Sample words for 'Action' genre: ['a', 'store', 'clerk', 'and', 'an', 'ice', 'cream', 'truck', 'driver', 'are', 'thrown', 'together', 'when', 'a', 'dying', 'scientist', 'entrusts', 'them', 'with', 'a']...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6738fae5",
        "outputId": "b00e1bbe-786c-485e-8e13-a930e5525553"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "genre_word_counts = {}\n",
        "for genre, words in genre_words.items():\n",
        "    genre_word_counts[genre] = Counter(words)\n",
        "\n",
        "print(\"Top 10 most frequent words per genre:\")\n",
        "print(\"------------------------------------\")\n",
        "for genre, counts in genre_word_counts.items():\n",
        "    print(f\"\\nGenre: {genre}\")\n",
        "\n",
        "    top_words = counts.most_common(10)\n",
        "    print(f\"  Top 10: {top_words}\")\n",
        "\n",
        "\n",
        "    filtered_counts = {word: count for word, count in counts.items() if count >= 3}\n",
        "    if filtered_counts:\n",
        "\n",
        "        filtered_counter = Counter(filtered_counts)\n",
        "        bottom_words = filtered_counter.most_common()[:-11:-1]\n",
        "        print(f\"  Bottom 10 (freq >= 3): {bottom_words}\")\n",
        "    else:\n",
        "        print(\"  No words with frequency >= 3 to display for bottom 10.\")\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 most frequent words per genre:\n",
            "------------------------------------\n",
            "\n",
            "Genre: Action\n",
            "  Top 10: [('the', 2698), ('a', 1743), ('to', 1443), ('and', 1238), ('of', 1214), ('in', 753), ('his', 715), ('is', 604), ('with', 393), ('an', 361)]\n",
            "  Bottom 10 (freq >= 3): [('joey', 3), ('doom', 3), ('mystery', 3), ('tongan', 3), ('shuttle', 3), ('serving', 3), ('mérida', 3), ('speed', 3), ('jill', 3), ('kitai', 3)]\n",
            "\n",
            "Genre: Adventure\n",
            "  Top 10: [('the', 2028), ('a', 1174), ('to', 1058), ('and', 970), ('of', 860), ('in', 532), ('his', 505), ('is', 377), ('with', 294), ('on', 258)]\n",
            "  Bottom 10 (freq >= 3): [('melvin', 3), ('arthur', 3), ('doom', 3), ('champion', 3), ('goons', 3), ('tongan', 3), ('chaney', 3), ('fast', 3), ('shuttle', 3), ('potter', 3)]\n",
            "\n",
            "Genre: Animation\n",
            "  Top 10: [('the', 678), ('a', 400), ('and', 368), ('to', 349), ('of', 294), ('in', 159), ('his', 150), ('is', 149), ('with', 102), ('he', 89)]\n",
            "  Bottom 10 (freq >= 3): [('garfield', 3), ('alex', 3), ('grandfather', 3), ('among', 3), ('retrieve', 3), ('mérida', 3), ('whose', 3), ('seen', 3), ('party', 3), ('beloved', 3)]\n",
            "\n",
            "Genre: Comedy\n",
            "  Top 10: [('the', 3174), ('a', 2597), ('to', 2027), ('and', 1903), ('of', 1524), ('in', 1067), ('his', 1050), ('is', 833), ('with', 724), ('her', 571)]\n",
            "  Bottom 10 (freq >= 3): [('leopold', 3), ('giselle', 3), ('garfield', 3), ('radhika', 3), ('rajveer', 3), ('selfproclaimed', 3), ('tickets', 3), ('leon', 3), ('juni', 3), ('debo', 3)]\n",
            "\n",
            "Genre: Crime\n",
            "  Top 10: [('the', 1222), ('a', 1076), ('to', 750), ('and', 680), ('of', 650), ('his', 432), ('in', 410), ('is', 341), ('he', 235), ('with', 211)]\n",
            "  Bottom 10 (freq >= 3): [('joey', 3), ('dominican', 3), ('wesley', 3), ('mccain', 3), ('stan', 3), ('popular', 3), ('serious', 3), ('hoover', 3), ('public', 3), ('federal', 3)]\n",
            "\n",
            "Genre: Documentary\n",
            "  Top 10: [('the', 298), ('and', 177), ('of', 164), ('a', 106), ('in', 106), ('to', 102), ('is', 51), ('from', 39), ('for', 32), ('on', 31)]\n",
            "  Bottom 10 (freq >= 3): [('afghanistan', 3), ('square', 3), ('wrestling', 3), ('stones', 3), ('action', 3), ('band', 3), ('melissa', 3), ('jimmy', 3), ('carl', 3), ('penguins', 3)]\n",
            "\n",
            "Genre: Drama\n",
            "  Top 10: [('the', 4474), ('a', 3554), ('to', 2495), ('and', 2488), ('of', 2390), ('in', 1609), ('his', 1503), ('is', 1150), ('her', 943), ('with', 887)]\n",
            "  Bottom 10 (freq >= 3): [('tess', 3), ('fandango', 3), ('coriolanus', 3), ('pig', 3), ('widows', 3), ('mill', 3), ('perez', 3), ('dominican', 3), ('neville', 3), ('mccain', 3)]\n",
            "\n",
            "Genre: Family\n",
            "  Top 10: [('the', 1342), ('a', 821), ('to', 719), ('and', 705), ('of', 554), ('in', 373), ('his', 331), ('is', 304), ('with', 234), ('he', 211)]\n",
            "  Bottom 10 (freq >= 3): [('giselle', 3), ('garfield', 3), ('royal', 3), ('radhika', 3), ('rajveer', 3), ('blanket', 3), ('tongan', 3), ('elliott', 3), ('mérida', 3), ('look', 3)]\n",
            "\n",
            "Genre: Fantasy\n",
            "  Top 10: [('the', 1020), ('a', 630), ('to', 562), ('and', 489), ('of', 428), ('in', 266), ('his', 254), ('is', 202), ('with', 171), ('he', 149)]\n",
            "  Bottom 10 (freq >= 3): [('leopold', 3), ('giselle', 3), ('doom', 3), ('truth', 3), ('jewel', 3), ('elliott', 3), ('hades', 3), ('center', 3), ('st', 3), ('gracey', 3)]\n",
            "\n",
            "Genre: Fiction\n",
            "  Top 10: [('the', 1354), ('a', 823), ('to', 667), ('of', 613), ('and', 563), ('in', 363), ('is', 280), ('his', 256), ('an', 182), ('with', 177)]\n",
            "  Bottom 10 (freq >= 3): [('leopold', 3), ('satellite', 3), ('neville', 3), ('hoyle', 3), ('st', 3), ('inner', 3), ('threatened', 3), ('saves', 3), ('speed', 3), ('physical', 3)]\n",
            "\n",
            "Genre: Foreign\n",
            "  Top 10: [('the', 80), ('a', 69), ('of', 45), ('and', 44), ('to', 30), ('his', 28), ('he', 28), ('is', 24), ('in', 23), ('with', 19)]\n",
            "  Bottom 10 (freq >= 3): [('widows', 3), ('voice', 3), ('mccain', 3), ('rebellion', 3), ('new', 3), ('don', 3), ('into', 3), ('encounters', 3), ('has', 3), ('streets', 3)]\n",
            "\n",
            "Genre: History\n",
            "  Top 10: [('the', 590), ('of', 289), ('and', 224), ('a', 209), ('to', 203), ('in', 171), ('his', 122), ('is', 70), ('with', 61), ('for', 54)]\n",
            "  Bottom 10 (freq >= 3): [('sophie', 3), ('tom', 3), ('hoover', 3), ('east', 3), ('had', 3), ('malone', 3), ('force', 3), ('katadreuffe', 3), ('eddie', 3), ('inspired', 3)]\n",
            "\n",
            "Genre: Horror\n",
            "  Top 10: [('the', 1111), ('a', 818), ('of', 564), ('to', 559), ('and', 458), ('in', 290), ('is', 248), ('her', 197), ('with', 170), ('his', 168)]\n",
            "  Bottom 10 (freq >= 3): [('billy', 3), ('carol', 3), ('disappearance', 3), ('reverend', 3), ('reports', 3), ('george', 3), ('moving', 3), ('callie', 3), ('underwater', 3), ('zoe', 3)]\n",
            "\n",
            "Genre: Movie\n",
            "  Top 10: [('the', 39), ('and', 22), ('of', 20), ('to', 20), ('a', 14), ('his', 10), ('their', 9), ('he', 8), ('is', 7), ('with', 7)]\n",
            "  Bottom 10 (freq >= 3): [('teenage', 3), ('from', 3), ('up', 3), ('family', 3), ('town', 3), ('mexico', 3), ('her', 3), ('jayne', 3), ('christmas', 4), ('daughter', 4)]\n",
            "\n",
            "Genre: Music\n",
            "  Top 10: [('the', 393), ('a', 236), ('and', 228), ('of', 205), ('to', 163), ('in', 134), ('his', 91), ('is', 67), ('her', 64), ('with', 63)]\n",
            "  Bottom 10 (freq >= 3): [('eddie', 3), ('harriet', 3), ('soon', 3), ('destroy', 3), ('tracy', 3), ('past', 3), ('stones', 3), ('university', 3), ('both', 3), ('change', 3)]\n",
            "\n",
            "Genre: Mystery\n",
            "  Top 10: [('the', 661), ('a', 564), ('of', 353), ('to', 352), ('and', 335), ('in', 227), ('is', 187), ('his', 166), ('he', 122), ('her', 118)]\n",
            "  Bottom 10 (freq >= 3): [('eva', 3), ('loyal', 3), ('hoyle', 3), ('michael', 3), ('gracey', 3), ('partner', 3), ('name', 3), ('cyber', 3), ('radio', 3), ('q', 3)]\n",
            "\n",
            "Genre: Romance\n",
            "  Top 10: [('the', 1509), ('a', 1422), ('to', 968), ('and', 958), ('of', 792), ('in', 637), ('his', 543), ('is', 463), ('her', 459), ('with', 408)]\n",
            "  Bottom 10 (freq >= 3): [('tess', 3), ('leopold', 3), ('giselle', 3), ('widows', 3), ('gerry', 3), ('albert', 3), ('radhika', 3), ('rajveer', 3), ('resist', 3), ('kellys', 3)]\n",
            "\n",
            "Genre: Science\n",
            "  Top 10: [('the', 1354), ('a', 823), ('to', 667), ('of', 613), ('and', 563), ('in', 363), ('is', 280), ('his', 256), ('an', 182), ('with', 177)]\n",
            "  Bottom 10 (freq >= 3): [('leopold', 3), ('satellite', 3), ('neville', 3), ('hoyle', 3), ('st', 3), ('inner', 3), ('threatened', 3), ('saves', 3), ('speed', 3), ('physical', 3)]\n",
            "\n",
            "Genre: TV\n",
            "  Top 10: [('the', 39), ('and', 22), ('of', 20), ('to', 20), ('a', 14), ('his', 10), ('their', 9), ('he', 8), ('is', 7), ('with', 7)]\n",
            "  Bottom 10 (freq >= 3): [('teenage', 3), ('from', 3), ('up', 3), ('family', 3), ('town', 3), ('mexico', 3), ('her', 3), ('jayne', 3), ('christmas', 4), ('daughter', 4)]\n",
            "\n",
            "Genre: Thriller\n",
            "  Top 10: [('the', 2505), ('a', 1989), ('to', 1430), ('of', 1258), ('and', 1221), ('in', 781), ('is', 645), ('his', 642), ('with', 385), ('her', 374)]\n",
            "  Bottom 10 (freq >= 3): [('melvin', 3), ('joey', 3), ('coriolanus', 3), ('eva', 3), ('champion', 3), ('words', 3), ('madison', 3), ('mccain', 3), ('hoyle', 3), ('inspired', 3)]\n",
            "\n",
            "Genre: War\n",
            "  Top 10: [('the', 359), ('a', 186), ('of', 184), ('to', 157), ('and', 152), ('in', 127), ('his', 78), ('is', 68), ('war', 53), ('on', 41)]\n",
            "  Bottom 10 (freq >= 3): [('russian', 3), ('join', 3), ('netherlands', 3), ('struggle', 3), ('nanking', 3), ('off', 3), ('mother', 3), ('learns', 3), ('adonijah', 3), ('prince', 3)]\n",
            "\n",
            "Genre: Western\n",
            "  Top 10: [('the', 183), ('a', 128), ('and', 90), ('to', 86), ('of', 83), ('in', 57), ('his', 49), ('is', 45), ('on', 30), ('for', 24)]\n",
            "  Bottom 10 (freq >= 3): [('chaney', 3), ('farm', 3), ('years', 3), ('three', 3), ('or', 3), ('adventure', 3), ('about', 3), ('tells', 3), ('mexican', 3), ('murder', 3)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TASK:-6"
      ],
      "metadata": {
        "id": "ZO8utm5gBVZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44cea08f",
        "outputId": "649c2d02-c6ed-4157-da02-6f1fe3eafae1"
      },
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "lr_model = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=42)\n",
        "ovr_classifier = OneVsRestClassifier(lr_model)\n",
        "\n",
        "ovr_classifier.fit(X_train, y_train_gen)\n",
        "\n",
        "print(\"OneVsRestClassifier (Logistic Regression) trained successfully on overview embeddings.\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OneVsRestClassifier (Logistic Regression) trained successfully on overview embeddings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad17ea6c",
        "outputId": "fa49653f-afc2-427e-9165-0e8faf414df6"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "feature_names = tfidf.get_feature_names_out()\n",
        "\n",
        "genre_top_words = {}\n",
        "\n",
        "for i, genre_name in enumerate(mlb.classes_):\n",
        "    lr_genre_model = ovr_classifier.estimators_[i]\n",
        "\n",
        "\n",
        "\n",
        "    word_coef_pairs = list(zip(feature_names, coefficients))\n",
        "\n",
        "    word_coef_pairs.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    top_positive_words = [(word, coef) for word, coef in word_coef_pairs if coef > 0][:10]\n",
        "\n",
        "    genre_top_words[genre_name] = top_positive_words\n",
        "\n",
        "\n",
        "print(\"Top 10 genre-indicative words (positive coefficients) for each genre:\")\n",
        "print(\"-------------------------------------------------------------------\")\n",
        "for genre, words_with_coefs in genre_top_words.items():\n",
        "    print(f\"\\nGenre: {genre}\")\n",
        "    if words_with_coefs:\n",
        "        for word, coef in words_with_coefs:\n",
        "            print(f\"  - {word}: {coef:.4f}\")\n",
        "    else:\n",
        "        print(\"  No strong positive indicative words found.\")\n",
        "\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 genre-indicative words (positive coefficients) for each genre:\n",
            "-------------------------------------------------------------------\n",
            "\n",
            "Genre: Action\n",
            "  - ad: 1.9503\n",
            "  - abused: 1.6766\n",
            "  - actors: 1.5788\n",
            "  - abraham: 1.1028\n",
            "  - abigail: 1.0618\n",
            "  - accomplish: 0.9446\n",
            "  - abandoned: 0.9388\n",
            "  - accuracy: 0.9000\n",
            "  - access: 0.8631\n",
            "  - abduct: 0.7877\n",
            "\n",
            "Genre: Adventure\n",
            "  - actor: 1.2253\n",
            "  - acclimated: 1.2189\n",
            "  - abolitionist: 1.2011\n",
            "  - accomplish: 1.0759\n",
            "  - accidentally: 1.0378\n",
            "  - acclaim: 1.0321\n",
            "  - acquaintances: 0.9548\n",
            "  - ada: 0.9020\n",
            "  - achieved: 0.8317\n",
            "  - abby: 0.7888\n",
            "\n",
            "Genre: Animation\n",
            "  - abolitionist: 1.8438\n",
            "  - accountant: 1.3388\n",
            "  - accused: 1.3347\n",
            "  - accepted: 1.1910\n",
            "  - ability: 1.1285\n",
            "  - abraham: 1.1208\n",
            "  - actor: 1.1186\n",
            "  - accident: 1.1130\n",
            "  - accidentally: 1.0810\n",
            "  - achieves: 0.9977\n",
            "\n",
            "Genre: Comedy\n",
            "  - absence: 1.2843\n",
            "  - accepted: 1.1636\n",
            "  - abba: 1.1288\n",
            "  - abaddon: 1.0083\n",
            "  - addictions: 0.9975\n",
            "  - ada: 0.9690\n",
            "  - abusive: 0.9265\n",
            "  - actor: 0.8723\n",
            "  - accuracy: 0.8455\n",
            "  - accountant: 0.8165\n",
            "\n",
            "Genre: Crime\n",
            "  - actors: 1.7682\n",
            "  - ab: 1.5094\n",
            "  - actress: 1.4750\n",
            "  - aarons: 1.0405\n",
            "  - abbie: 0.9933\n",
            "  - abusive: 0.9671\n",
            "  - abortion: 0.9443\n",
            "  - accept: 0.9430\n",
            "  - accident: 0.9234\n",
            "  - actions: 0.8227\n",
            "\n",
            "Genre: Documentary\n",
            "  - addiction: 1.8192\n",
            "  - academy: 1.6085\n",
            "  - acting: 1.5854\n",
            "  - abortion: 1.3385\n",
            "  - acclaimed: 1.3032\n",
            "  - acts: 1.2019\n",
            "  - activities: 1.2013\n",
            "  - abilities: 1.0951\n",
            "  - actionpacked: 1.0641\n",
            "  - abuse: 1.0330\n",
            "\n",
            "Genre: Drama\n",
            "  - add: 1.6603\n",
            "  - actions: 1.5462\n",
            "  - accompanying: 0.9808\n",
            "  - aaron: 0.8798\n",
            "  - abrupt: 0.8486\n",
            "  - accompanied: 0.8308\n",
            "  - action: 0.7917\n",
            "  - aaa: 0.7885\n",
            "  - academic: 0.7829\n",
            "  - absolute: 0.7688\n",
            "\n",
            "Genre: Family\n",
            "  - activist: 1.6135\n",
            "  - accidentally: 1.4689\n",
            "  - abusive: 1.4483\n",
            "  - accepted: 1.2723\n",
            "  - activities: 1.2357\n",
            "  - abilities: 1.2072\n",
            "  - abuse: 1.2052\n",
            "  - academy: 1.1323\n",
            "  - abrupt: 1.0712\n",
            "  - adapted: 1.0571\n",
            "\n",
            "Genre: Fantasy\n",
            "  - abduct: 1.6081\n",
            "  - actor: 1.2753\n",
            "  - accused: 1.2380\n",
            "  - accidentally: 1.1269\n",
            "  - accompanied: 0.9268\n",
            "  - adam: 0.8891\n",
            "  - achieved: 0.7678\n",
            "  - abolitionist: 0.7388\n",
            "  - aarons: 0.7299\n",
            "  - accepts: 0.6950\n",
            "\n",
            "Genre: Fiction\n",
            "  - abduct: 2.1061\n",
            "  - act: 1.7837\n",
            "  - abbate: 1.7341\n",
            "  - ad: 1.7213\n",
            "  - ada: 1.4499\n",
            "  - abraham: 1.3594\n",
            "  - abortion: 1.2457\n",
            "  - adapt: 1.2397\n",
            "  - achieved: 1.0423\n",
            "  - abagnale: 1.0304\n",
            "\n",
            "Genre: Foreign\n",
            "  - act: 1.2036\n",
            "  - add: 1.1241\n",
            "  - acts: 1.1227\n",
            "  - acquitted: 0.8567\n",
            "  - abandoned: 0.7798\n",
            "  - acceptance: 0.7345\n",
            "  - actions: 0.7028\n",
            "  - abandoning: 0.6437\n",
            "  - aarons: 0.6341\n",
            "  - abbate: 0.6211\n",
            "\n",
            "Genre: History\n",
            "  - accompanied: 1.7640\n",
            "  - access: 1.5512\n",
            "  - accessible: 1.4795\n",
            "  - aaron: 1.4073\n",
            "  - accidental: 1.1912\n",
            "  - acceptance: 1.1006\n",
            "  - ability: 1.0988\n",
            "  - abigail: 1.0946\n",
            "  - adapt: 1.0856\n",
            "  - actions: 1.0654\n",
            "\n",
            "Genre: Horror\n",
            "  - abortion: 1.9028\n",
            "  - ada: 1.4589\n",
            "  - activist: 1.3612\n",
            "  - abagnale: 1.3516\n",
            "  - accept: 1.3382\n",
            "  - abaddon: 1.3269\n",
            "  - adams: 1.3039\n",
            "  - accessories: 1.2976\n",
            "  - accidental: 1.1463\n",
            "  - abba: 1.1099\n",
            "\n",
            "Genre: Movie\n",
            "  - actually: 0.6745\n",
            "  - abducts: 0.6533\n",
            "  - abolitionist: 0.6276\n",
            "  - activist: 0.6049\n",
            "  - adaptation: 0.4968\n",
            "  - accessible: 0.3534\n",
            "  - acting: 0.3355\n",
            "  - adaption: 0.3298\n",
            "  - adapt: 0.3156\n",
            "  - adaline: 0.3114\n",
            "\n",
            "Genre: Music\n",
            "  - addictions: 1.8444\n",
            "  - absolute: 1.6926\n",
            "  - abroad: 1.2169\n",
            "  - accessories: 1.1958\n",
            "  - aarons: 1.1219\n",
            "  - actions: 1.1028\n",
            "  - abuse: 1.0662\n",
            "  - accidents: 0.9503\n",
            "  - abducted: 0.9412\n",
            "  - accuracy: 0.9225\n",
            "\n",
            "Genre: Mystery\n",
            "  - acclaimed: 1.9299\n",
            "  - abortion: 1.2965\n",
            "  - acquitted: 1.2854\n",
            "  - abandons: 1.2383\n",
            "  - activists: 1.1050\n",
            "  - abagnale: 1.0627\n",
            "  - accept: 1.0100\n",
            "  - actress: 0.9874\n",
            "  - add: 0.9473\n",
            "  - accidental: 0.8620\n",
            "\n",
            "Genre: Romance\n",
            "  - add: 2.2707\n",
            "  - aaron: 1.4894\n",
            "  - addictions: 1.0774\n",
            "  - actually: 1.0308\n",
            "  - abducts: 0.9559\n",
            "  - absolute: 0.9437\n",
            "  - acquaintance: 0.8458\n",
            "  - abusive: 0.6962\n",
            "  - able: 0.6473\n",
            "  - abbas: 0.6362\n",
            "\n",
            "Genre: Science\n",
            "  - abduct: 2.1061\n",
            "  - act: 1.7837\n",
            "  - abbate: 1.7341\n",
            "  - ad: 1.7213\n",
            "  - ada: 1.4499\n",
            "  - abraham: 1.3594\n",
            "  - abortion: 1.2457\n",
            "  - adapt: 1.2397\n",
            "  - achieved: 1.0423\n",
            "  - abagnale: 1.0304\n",
            "\n",
            "Genre: TV\n",
            "  - actually: 0.6745\n",
            "  - abducts: 0.6533\n",
            "  - abolitionist: 0.6276\n",
            "  - activist: 0.6049\n",
            "  - adaptation: 0.4968\n",
            "  - accessible: 0.3534\n",
            "  - acting: 0.3355\n",
            "  - adaption: 0.3298\n",
            "  - adapt: 0.3156\n",
            "  - adaline: 0.3114\n",
            "\n",
            "Genre: Thriller\n",
            "  - abandons: 1.5940\n",
            "  - accept: 1.2168\n",
            "  - abagnale: 1.1426\n",
            "  - abbas: 1.1045\n",
            "  - actions: 1.0679\n",
            "  - actress: 0.9568\n",
            "  - acclaimed: 0.9359\n",
            "  - abortion: 0.9316\n",
            "  - adaline: 0.9241\n",
            "  - ada: 0.8847\n",
            "\n",
            "Genre: War\n",
            "  - abroad: 1.8399\n",
            "  - activities: 1.7980\n",
            "  - activist: 1.6481\n",
            "  - aaron: 1.5254\n",
            "  - accused: 1.2314\n",
            "  - acceptance: 1.2181\n",
            "  - acquitted: 1.0860\n",
            "  - actions: 1.0807\n",
            "  - ability: 1.0493\n",
            "  - abused: 1.0031\n",
            "\n",
            "Genre: Western\n",
            "  - actually: 2.0164\n",
            "  - abigail: 1.7163\n",
            "  - abbate: 1.4999\n",
            "  - abby: 1.2558\n",
            "  - abducts: 1.1264\n",
            "  - actors: 1.0552\n",
            "  - acceptance: 1.0076\n",
            "  - abolitionist: 0.9979\n",
            "  - abandons: 0.9216\n",
            "  - addictions: 0.8373\n"
          ]
        }
      ]
    }
  ]
}